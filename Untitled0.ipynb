{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOn2c+BPICuxyQLm+LFfObq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pythonimeislabor/repo1/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0nBWsvTT9wH"
      },
      "source": [
        "# Datensatz von kaggle herunterladen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXsRTyAXThfZ",
        "outputId": "6491446f-766c-4e76-d4f4-f8eff4f43043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kaggle.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile kaggle.json\n",
        "{\"username\":\"lutze3\",\"key\":\"c1b954a36f5402b976973271cb154a2f\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a-dfnFyCT8Qh"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!kaggle datasets download -d jcprogjava/handwritten-digits-dataset-not-in-mnist\n",
        "!unzip handwritten-digits-dataset-not-in-mnist.zip\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGNR29egXEnh"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyHIeBq2T8bS"
      },
      "outputs": [],
      "source": [
        "import cv2 # Bildbearbeitung\n",
        "import matplotlib.pyplot as plt # Bilder anzeigen\n",
        "import os # Um Bilder in den Ordnern zu finden\n",
        "import numpy as np # Für Arrays mit denen Tensorflow umgehen kann\n",
        "import tensorflow as tf # für deep-learning / neuronale Netze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKEV1go0fEkC"
      },
      "source": [
        "# Trainingsdatensatz generieren\n",
        "Ein neuronales Netz braucht viele Trainingsdaten um Zusammenhänge zu erkennen.<br>\n",
        "Dazu werden 2 Listen erstellt. Liste X enthält alle Bilder, Liste Y die zugehörigen Zahlen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"dataset\") # os.listdir gibt eine liste mit allen Ordnern und Dateien im angegebenen Verzeichnis zurück"
      ],
      "metadata": {
        "id": "pY_JI8lRoGCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2705b877-4ed7-4b17-9702-11bd1d9f0fdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['8', '7', '9', '5', '1', '2', '0', '4', '3', '6']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "dttonN4KdDIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7d9c70-28b9-4cd0-e25e-1d85c1e3ed34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zahl ist 0 - Der Pfad ist dataset/0/0/\n",
            "zahl ist 1 - Der Pfad ist dataset/1/1/\n",
            "zahl ist 2 - Der Pfad ist dataset/2/2/\n",
            "zahl ist 3 - Der Pfad ist dataset/3/3/\n",
            "zahl ist 4 - Der Pfad ist dataset/4/4/\n",
            "zahl ist 5 - Der Pfad ist dataset/5/5/\n",
            "zahl ist 6 - Der Pfad ist dataset/6/6/\n",
            "zahl ist 7 - Der Pfad ist dataset/7/7/\n",
            "zahl ist 8 - Der Pfad ist dataset/8/8/\n",
            "zahl ist 9 - Der Pfad ist dataset/9/9/\n"
          ]
        }
      ],
      "source": [
        "#X = [bild1, bild2, bild3]\n",
        "#Y = [Beschriftung1, Beschriftung2, Beschriftung3]\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def linie_zeichnen(bild): # Zeichnet eine verunstaltende Linie auf ein Bild\n",
        "  p1_x = np.random.randint(0,29)\n",
        "  p1_y = np.random.randint(0,29)\n",
        "  p2_x = np.random.randint(0,29)\n",
        "  p2_y = np.random.randint(0,29)\n",
        "  bild_mit_linie = cv2.line(bild.copy(), (p1_x, p1_y), (p2_x, p2_y), (1))\n",
        "  return bild_mit_linie\n",
        "\n",
        "def lade_bild(pfad): # Bild laden und vorverarbeiten\n",
        "  bild = cv2.imread(pfad, cv2.IMREAD_UNCHANGED) # bild lesen vom rgba-format\n",
        "  bild_in_grau = bild[:,:,3] # Alpha-Wert herausfiltern\n",
        "  bild_0_1 = bild_in_grau / 255 # bild zwischen 0 und 1 skalieren\n",
        "  rauschen = np.random.normal(size=(28,28)) / 20 # Zufallszahlen mit Normalverteilung generieren in der Form 28x28\n",
        "  bild_mit_rauschen = bild_0_1 + rauschen # Elementweise Addition vom Bild und dem Rauschen durchführen\n",
        "\n",
        "  l1 = linie_zeichnen(bild_mit_rauschen)\n",
        "  l2 = linie_zeichnen(l1)\n",
        "  l3 = linie_zeichnen(l2)\n",
        "\n",
        "  return l3 # Bild an den Aufruf zurückgeben\n",
        "\n",
        "\n",
        "for zahl in range(10): # Wir haben ordner von 0 bis 9\n",
        "  pfad = \"dataset/\"+str(zahl)+\"/\"+str(zahl) + \"/\" # Pfad zusammenbauen\n",
        "  print(\"zahl ist\", zahl, \"- Der Pfad ist\", pfad)\n",
        "  alle_bilder_namen = os.listdir(pfad) # alle bilder im pfad auflisten\n",
        "  for name in alle_bilder_namen: # alle bilder in dem Ordner durchgehen\n",
        "    pfad_zum_bild = pfad + name \n",
        "    bild = lade_bild(pfad_zum_bild)\n",
        "\n",
        "    X.append(bild) # Das Bild an X anhängen\n",
        "    Y.append(zahl) # Die zugehörige Zahl an Y anhängen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Es gibt\", len(Y),\"Trainingsbilder\")"
      ],
      "metadata": {
        "id": "dbfx3ak8o2M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437e47cd-a82f-4b7d-8083-38f0ad9afed4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Es gibt 107730 Trainingsbilder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6kMzl5UQg0KP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b86e15e5-b51f-4b6c-9380-439c48e4e4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Es wird das Bild mit dem index 100000 angezeigt\n",
            "Y ist  6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "index = 100000\n",
        "\n",
        "print(\"Es wird das Bild mit dem index\", index, \"angezeigt\")\n",
        "plt.imshow(X[index], cmap = \"gray\"), \n",
        "print(\"Y ist \", Y[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0xNT0n6i01X8"
      },
      "outputs": [],
      "source": [
        "# listen in numpy arrays umwandeln\n",
        "Y = np.array(Y) # numpy arrays sind für viele Elemente eine bessere Speichermethode\n",
        "X = np.array(X) # tensorflow benötigt numpy arrays und kann nicht mit listen arbeiten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "für das Training werden die Trainingsdaten in Trainingsdaten und Validierungsdaten aufgeteilt. Das neuronale Netz wird auf 80% der Daten trainiert und auf die anderen 20% getestet. Wenn es auf den anderen 20% gut ist, hat das neuronale Netz das Konzept von den Bildern verstanden. wenn es nur auf den Trainingsdaten gut ist und die Testdaten nicht klassifizieren kann, hat es nicht gut gelernt. <br>Tensorflow nimmt immer die letzten x% im Datensatz als Validierungsdaten. In diesem Fall sind die letzten 20% alle Bilder der 8 und der 9. Es würde also von 0 - 7 alles lernen und auf 8 und 9 getestet werden. Das kann so nicht funktionieren, denn wenn das Netzwerk nie eine 8 oder 9 in den Trainingsdaten gesehen hat wird es lernen dass es solche Zahlen nicht gibt. Also müssen die Trainingsdaten gemischt werden um zufällige Zahlen als Validierungsdaten zu erhalten"
      ],
      "metadata": {
        "id": "aXOjWn5HpX-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X und Y gleichmäßig mischen\n",
        "# X und Y werden so gemischt, dass Y[index] die Zahl enthält die in X[index] gespeichert ist\n",
        "p = np.random.permutation(Y.shape[0]) \n",
        "X = X[p]\n",
        "Y = Y[p] "
      ],
      "metadata": {
        "id": "ZQANFYQ5pUyK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zufallsveränderungen auf jedes Bild vor dem Training anwenden um allgemeine Lösungen zu finden"
      ],
      "metadata": {
        "id": "cJ7q7wf5wu2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_gedreht = tf.keras.layers.RandomRotation((-0.1, 0.1))(X[0].reshape(1,28,28,1), training=True)\n",
        "random_verschieben = tf.keras.layers.RandomTranslation((-0.2,0.2), (-0.2,0.2)) (random_gedreht, training=True)\n",
        "random_Zoom = tf.keras.layers.RandomZoom((-0.2,0.3), (-0.2,0.3)) (random_verschieben, training=True)\n",
        "\n",
        "plt.imshow(random_Zoom.numpy()[0].reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BMx7YBADwtxe",
        "outputId": "73405094-9d93-4de5-e016-288d0c147c13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc1a3334650>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tspW2wbat0GX"
      },
      "source": [
        "# Neuronales Netzwerk bauen und trainieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfSDw5Gat2rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fb9b1b-5f40-4625-822c-e8e878d7a940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " random_rotation_45 (RandomR  (None, 28, 28, 1)        0         \n",
            " otation)                                                        \n",
            "                                                                 \n",
            " random_translation_19 (Rand  (None, 28, 28, 1)        0         \n",
            " omTranslation)                                                  \n",
            "                                                                 \n",
            " random_zoom_14 (RandomZoom)  (None, 28, 28, 1)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 11, 11, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                25664     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,354\n",
            "Trainable params: 29,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputlayer = tf.keras.layers.Input(shape=(28,28)) # unser Bild hat die Form [Höhe, Breite]\n",
        "\n",
        "bild_3_d = tf.keras.layers.Reshape((28,28,1)) (inputlayer)\n",
        "\n",
        "random_gedreht = tf.keras.layers.RandomRotation((-0.1, 0.1))(bild_3_d)\n",
        "random_verschieben = tf.keras.layers.RandomTranslation((-0.3,0.3), (-0.3,0.3)) (random_gedreht)\n",
        "random_Zoom = tf.keras.layers.RandomZoom((-0.2,0.3), (-0.2,0.3)) (random_verschieben)\n",
        "\n",
        "filter_1 = tf.keras.layers.Conv2D(16,3, activation=\"relu\") (random_Zoom)\n",
        "drop1 = tf.keras.layers.Dropout(0.3)(filter_1)\n",
        "maxpoollayer1 = tf.keras.layers.MaxPooling2D() (drop1)\n",
        "\n",
        "\n",
        "filter_2 = tf.keras.layers.Conv2D(16,3, activation=\"relu\") (maxpoollayer1)\n",
        "drop2 = tf.keras.layers.Dropout(0.3)(filter_2)\n",
        "maxpoollayer2 = tf.keras.layers.MaxPooling2D() (drop2)\n",
        "\n",
        "\n",
        "platt = tf.keras.layers.Flatten()(maxpoollayer2)\n",
        "\n",
        "x = tf.keras.layers.Dense(64,activation=\"relu\")(platt)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(16,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "output = tf.keras.layers.Dense(10,activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputlayer, output)\n",
        "print(\"\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V44YHlbXvwZP"
      },
      "outputs": [],
      "source": [
        "fehlerfunktion = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimierer = tf.keras.optimizers.SGD(0.001, momentum = 0.95)\n",
        "model.compile(optimierer, fehlerfunktion, metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S2tL87avxb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5a9d9e-767b-4e3f-adb8-7f65ffc90b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1347/1347 [==============================] - 48s 34ms/step - loss: 2.2664 - accuracy: 0.1486 - val_loss: 2.0506 - val_accuracy: 0.2367\n",
            "Epoch 2/10\n",
            "1347/1347 [==============================] - 46s 34ms/step - loss: 1.8922 - accuracy: 0.3090 - val_loss: 1.0052 - val_accuracy: 0.6264\n",
            "Epoch 3/10\n",
            "1347/1347 [==============================] - 46s 34ms/step - loss: 1.3412 - accuracy: 0.5059 - val_loss: 0.3412 - val_accuracy: 0.8818\n",
            "Epoch 4/10\n",
            "1347/1347 [==============================] - 46s 34ms/step - loss: 1.0210 - accuracy: 0.6279 - val_loss: 0.2230 - val_accuracy: 0.9069\n",
            "Epoch 5/10\n",
            "1347/1347 [==============================] - 46s 34ms/step - loss: 0.8321 - accuracy: 0.7020 - val_loss: 0.2250 - val_accuracy: 0.9102\n",
            "Epoch 6/10\n",
            "1347/1347 [==============================] - 45s 34ms/step - loss: 0.7102 - accuracy: 0.7534 - val_loss: 0.0532 - val_accuracy: 0.9867\n",
            "Epoch 7/10\n",
            "1347/1347 [==============================] - 45s 34ms/step - loss: 0.6061 - accuracy: 0.7919 - val_loss: 0.0363 - val_accuracy: 0.9916\n",
            "Epoch 8/10\n",
            "1347/1347 [==============================] - 45s 34ms/step - loss: 0.5523 - accuracy: 0.8118 - val_loss: 0.0196 - val_accuracy: 0.9971\n",
            "Epoch 9/10\n",
            "1347/1347 [==============================] - 46s 34ms/step - loss: 0.4940 - accuracy: 0.8347 - val_loss: 0.0144 - val_accuracy: 0.9978\n",
            "Epoch 10/10\n",
            "1347/1347 [==============================] - 45s 34ms/step - loss: 0.4541 - accuracy: 0.8483 - val_loss: 0.0104 - val_accuracy: 0.9981\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4eb1dd1190>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "model.fit(X, Y, batch_size = 64, epochs = 10, validation_split = 0.2) # Parameter optimieren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV5Ckw9ld6JM"
      },
      "source": [
        "# Test mit selbstgemaltem Bild\n",
        "Male eine Zahl mit Paint und lade das Bild in das Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifjD08Wod-Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0eeb3059-1fa3-48e0-963a-cd6ba392b09e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALNElEQVR4nO3dT8gc933H8fenbnJxDJZrKoTiVmnwrQepCJ9MkSkJri9yLiY6KTTw5FCX9BaTHmIoAROa9BhQsIlaUoeAbSxCaeIaEecULNuqLdskdmOZSMgSRhV1Tknsbw/PqDyxn919tP+l7/sFy87O7O58NdJH85uZnd8vVYWkG98frLoAScth2KUmDLvUhGGXmjDsUhN/uMyVJfHUv7RgVZXt5s+0Z09yb5KfJ3kzyUOzfJekxcq019mT3AT8AvgMcA54HjhSVa+N+Yx7dmnBFrFnvwt4s6p+WVW/Ab4PHJ7h+yQt0Cxh3wv8asvrc8O835NkI8mpJKdmWJekGS38BF1VHQOOgc14aZVm2bOfB+7Y8vqTwzxJa2iWsD8P3JnkU0k+DnweODGfsiTN29TN+Kr6XZIHgR8BNwGPVdWrc6tM0lxNfeltqpV5zC4t3EJ+VCPp+mHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdamLq8dkBkpwF3gPeB35XVQfnUZSk+Zsp7IN7qurdOXyPpAWyGS81MWvYC/hxkheSbGz3hiQbSU4lOTXjuiTNIFU1/YeTvVV1PskfA88Af1dVz415//Qrk7QjVZXt5s+0Z6+q88PzJeAp4K5Zvk/S4kwd9iQ3J7nl6jTwWeDMvAqTNF+znI3fDTyV5Or3/FtV/cdcqpI0dzMds1/zyjxmlxZuIcfskq4fhl1qwrBLTRh2qQnDLjUxjxthdAN76aWXZvr8gQMH5lSJZuWeXWrCsEtNGHapCcMuNWHYpSYMu9SEYZea8Dp7c5Ouo+/bt2/s8ltvvXWO1WiR3LNLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhNeZ78BjLtWvn///rGfvXLlytjlu3btGrt8mb0Tazbu2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCa+zr4FJ94SfPHly7PJx95wPQ2pLk/fsSR5LcinJmS3zbkvyTJI3hufxv7yQtHI7acZ/F7j3Q/MeAp6tqjuBZ4fXktbYxLBX1XPA5Q/NPgwcH6aPA/fPuS5JczbtMfvuqrowTL8D7B71xiQbwMaU65E0JzOfoKuqSjLyboiqOgYcAxj3PkmLNe2lt4tJ9gAMz5fmV5KkRZg27CeAo8P0UeDp+ZQjaVEmNuOTPA4cAm5Pcg74GvAI8IMkXwTeBh5YZJHrblLf67PeU37PPfeMXX769Omxy2cx6c82qXatj4lhr6ojIxb91ZxrkbRA/lxWasKwS00YdqkJwy41YdilJrLMroDX+Rd0k24jPXTo0Mhls3bHvM4m/fvwFtr1U1Xb/qW4Z5eaMOxSE4ZdasKwS00YdqkJwy41YdilJrzOrrG8zn798Tq71Jxhl5ow7FIThl1qwrBLTRh2qQnDLjXhkM3NTRou2q6ibxzu2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCa+zNzepv/xJw0Xr+jFxz57ksSSXkpzZMu/hJOeTnB4e9y22TEmz2kkz/rvAvdvM/+eq2j88/n2+ZUmat4lhr6rngMtLqEXSAs1ygu7BJC8PzfyRg5kl2UhyKsmpGdYlaUbThv3bwKeB/cAF4Juj3lhVx6rqYFUdnHJdkuZgqrBX1cWqer+qPgC+A9w137IkzdtUYU+yZ8vLzwFnRr1X0nqY2G98kseBQ8DtwEXga8Pr/UABZ4EvVdWFiSuz3/ilm3S/+ltvvTV2+fU8tnxXo/qNn/ijmqo6ss3sR2euSNJS+XNZqQnDLjVh2KUmDLvUhGGXmvAW1xuct7DqKvfsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9TExFtc57oyb3Fduh3cwrykSrQso25xdc8uNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qYmJYU9yR5KTSV5L8mqSLw/zb0vyTJI3hmcH8pbW2MSeapLsAfZU1YtJbgFeAO4HvgBcrqpHkjwE7Kqqr0z4LnuqWTJ7quln6p5qqupCVb04TL8HvA7sBQ4Dx4e3HWfzPwBJa+qaxnpLsg84APwM2F1VF4ZF7wC7R3xmA9iYvkRJ87DjDieTfAL4CfD1qnoyyZWqunXL8v+pqrHH7Tbjl89mfD8zdTiZ5GPAE8D3qurJYfbF4Xj+6nH9pXkUKmkxdnI2PsCjwOtV9a0ti04AR4fpo8DT8y9P0rzs5Gz83cBPgVeAD4bZX2XzuP0HwJ8AbwMPVNXlCd9lM37JbMb3M6oZ7yARNzjD3o+DREjNGXapCcMuNWHYpSYMu9TENf1cVuvp5MmTI5dduXJliZVonblnl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmvOtNusF415vUnGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41sZPx2e9IcjLJa0leTfLlYf7DSc4nOT087lt8uZKmtZPx2fcAe6rqxSS3AC8A9wMPAL+uqn/a8crsvEJauFGdV0wcEaaqLgAXhun3krwO7J1veZIW7ZqO2ZPsAw4APxtmPZjk5SSPJdk14jMbSU4lOTVTpZJmsuM+6JJ8AvgJ8PWqejLJbuBdoIB/ZLOp/zcTvsNmvLRgo5rxOwp7ko8BPwR+VFXf2mb5PuCHVfXnE77HsEsLNnWHk0kCPAq8vjXow4m7qz4HnJm1SEmLs5Oz8XcDPwVeAT4YZn8VOALsZ7MZfxb40nAyb9x3uWeXFmymZvy8GHZp8ew3XmrOsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71MTEDifn7F3g7S2vbx/mraN1rW1d6wJrm9Y8a/vTUQuWej/7R1aenKqqgysrYIx1rW1d6wJrm9ayarMZLzVh2KUmVh32Yyte/zjrWtu61gXWNq2l1LbSY3ZJy7PqPbukJTHsUhMrCXuSe5P8PMmbSR5aRQ2jJDmb5JVhGOqVjk83jKF3KcmZLfNuS/JMkjeG523H2FtRbWsxjPeYYcZXuu1WPfz50o/Zk9wE/AL4DHAOeB44UlWvLbWQEZKcBQ5W1cp/gJHkL4FfA/9ydWitJN8ALlfVI8N/lLuq6itrUtvDXOMw3guqbdQw419ghdtunsOfT2MVe/a7gDer6pdV9Rvg+8DhFdSx9qrqOeDyh2YfBo4P08fZ/MeydCNqWwtVdaGqXhym3wOuDjO+0m03pq6lWEXY9wK/2vL6HOs13nsBP07yQpKNVRezjd1bhtl6B9i9ymK2MXEY72X60DDja7Ptphn+fFaeoPuou6vqL4C/Bv52aK6updo8Bluna6ffBj7N5hiAF4BvrrKYYZjxJ4C/r6r/3bpsldtum7qWst1WEfbzwB1bXn9ymLcWqur88HwJeIrNw451cvHqCLrD86UV1/P/qupiVb1fVR8A32GF224YZvwJ4HtV9eQwe+Xbbru6lrXdVhH254E7k3wqyceBzwMnVlDHRyS5eThxQpKbgc+yfkNRnwCODtNHgadXWMvvWZdhvEcNM86Kt93Khz+vqqU/gPvYPCP/38A/rKKGEXX9GfBfw+PVVdcGPM5ms+63bJ7b+CLwR8CzwBvAfwK3rVFt/8rm0N4vsxmsPSuq7W42m+gvA6eHx32r3nZj6lrKdvPnslITnqCTmjDsUhOGXWrCsEtNGHapCcMuNWHYpSb+DyidzdlpnSgDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "bild = cv2.imread(\"Untitled.png\", cv2.IMREAD_GRAYSCALE) # bild mit dem Namen untitled.png lesen im graustufen-format\n",
        "bild = cv2.resize(bild, (28,28))\n",
        "bild_0_1 = 1 - bild / 255 # bild zwischen 0 und 1 skalieren\n",
        "plt.imshow(bild_0_1, cmap = \"gray\")\n",
        "bild_0_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKZb7f-FegmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860a6591-abbb-4279-e876-224c1daa30a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Entscheidungen sind: tf.Tensor(\n",
            "[[1.3818390e-06 1.6409464e-03 6.9319196e-02 1.8468123e-02 4.1947034e-03\n",
            "  1.7648928e-06 1.1841603e-07 9.0197378e-01 1.2475853e-06 4.3986030e-03]], shape=(1, 10), dtype=float32)\n",
            "Das ist die Zahl: 7\n"
          ]
        }
      ],
      "source": [
        "bild_batch = np.reshape(bild_0_1,(1,28,28)) # tensorflow braucht ein array von Inputs\n",
        "\n",
        "entscheidungen = model(bild_batch)\n",
        "print(\"Die Entscheidungen sind:\", entscheidungen)\n",
        "print(\"Das ist die Zahl:\", np.argmax(entscheidungen))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\") # Netzwerk und Parameter speichern"
      ],
      "metadata": {
        "id": "U9RCAaCTKeCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X6dDGDQMcrIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wpm4z1jytD-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7C1j3wZstThE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}