{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pythonimeislabor/repo1/blob/main/erstes_neuronales_Netz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0nBWsvTT9wH"
      },
      "source": [
        "# Datensatz von kaggle herunterladen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXsRTyAXThfZ",
        "outputId": "85cb28a4-3c84-4969-83df-d62e46b0c517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kaggle.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile kaggle.json\n",
        "{\"username\":\"lutze3\",\"key\":\"c1b954a36f5402b976973271cb154a2f\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-dfnFyCT8Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34840cef-193f-44ec-fed6-2519aad309e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "handwritten-digits-dataset-not-in-mnist.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  handwritten-digits-dataset-not-in-mnist.zip\n",
            "replace dataset/0/0/0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!kaggle datasets download -d jcprogjava/handwritten-digits-dataset-not-in-mnist\n",
        "!unzip handwritten-digits-dataset-not-in-mnist.zip\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGNR29egXEnh"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyHIeBq2T8bS"
      },
      "outputs": [],
      "source": [
        "import cv2 # Bildbearbeitung\n",
        "import matplotlib.pyplot as plt # Bilder anzeigen\n",
        "import os # Um Bilder in den Ordnern zu finden\n",
        "import numpy as np # Für Arrays mit denen Tensorflow umgehen kann\n",
        "import tensorflow as tf # für deep-learning / neuronale Netze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMnRf2OGXHr6"
      },
      "source": [
        "# Testweise ein Bild laden und anzeigen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Bilder sind im RGBA-format gespeichert. Die RGB-Farben sind alle auf 0 gesetzt. Der Alpha-Wert speichert in diesem Fall die Helligkeit eines Pixels.<br>\n",
        "Um ein Bild im RGBA-Format zu laden muss das IMREAD_UNCHANGED an imread() übergeben werden. Ohne IMREAD_UNCHANGED würde opencv nur RGB lesen und den wichtigen Alpha-Wert weglassen"
      ],
      "metadata": {
        "id": "0eM5uLKJj1zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjgrEq8OXEKZ"
      },
      "outputs": [],
      "source": [
        "dateipfad = \"dataset/5/5/0.png\"\n",
        "bild = cv2.imread(dateipfad, cv2.IMREAD_UNCHANGED) # bild lesen\n",
        "plt.imshow(bild)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Das Bild hat 3 Dimensionen: Höhe, Breite und die 4 Farbwerte.<br> Mit bild[0] würden wir die erste Zeile im Bild erhalten. Mit Bild[0][0] oder bild[0,0] würden wir den ersten Pixel oben links im Bild erhalten.<br>\n",
        "bild[ : , : , 3] bedeutet, die Pixel mit Y von Anfang bis Ende, X von Anfang bis Ende, Farbkanal an der Stelle 3"
      ],
      "metadata": {
        "id": "O0w1m5f2k1n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bild[0, 0] # Der Pixel mit y = 0 und x = 0"
      ],
      "metadata": {
        "id": "1T31CF8wmRZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bild[0, 0:2] # Die Pixel mit y = 0 und x = 0 bis 2, also X = 1 oder x = 2"
      ],
      "metadata": {
        "id": "Kg96B3FnmYae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCk1gG7qXyvU"
      },
      "outputs": [],
      "source": [
        "bild_in_grau = bild[:,:,3] # Y von Anfang bis Ende, X von Anfang bis Ende, c nur mit dem Index 3\n",
        "print(bild_in_grau.shape)\n",
        "plt.imshow(bild_in_grau, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Das Bild ist im UINT8-Format gespeichert. Jeder Pixel besteht nun aus 8 Bits, kann also Werte von 0 bis 255 annehmen. Für das neuronale Netz sollten wir diese Werte zwischen 0 und 1 bringen"
      ],
      "metadata": {
        "id": "37JP5L4LnEBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnMgME0GcwFo"
      },
      "outputs": [],
      "source": [
        "print(\"Das Bild hat den Speichertyp\", bild_in_grau.dtype)\n",
        "bild_0_1 = bild_in_grau / 255 # bild zwischen 0 und 1 skalieren - jeder Wert im array wird durch 255 geteilt\n",
        "plt.imshow(bild_0_1, cmap = \"gray\") # Das Bild hat sich nicht verändert, aber das speicherformat ist nun vom type float\n",
        "print(\"Das Bild hat nach dem skalieren den Speichertyp\", bild_0_1.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKEV1go0fEkC"
      },
      "source": [
        "# Trainingsdatensatz generieren\n",
        "Ein neuronales Netz braucht viele Trainingsdaten um Zusammenhänge zu erkennen.<br>\n",
        "Dazu werden 2 Listen erstellt. Liste X enthält alle Bilder, Liste Y die zugehörigen Zahlen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"dataset\") # os.listdir gibt eine liste mit allen Ordnern und Dateien im angegebenen Verzeichnis zurück"
      ],
      "metadata": {
        "id": "pY_JI8lRoGCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dttonN4KdDIC"
      },
      "outputs": [],
      "source": [
        "#X = [bild1, bild2, bild3]\n",
        "#Y = [Beschriftung1, Beschriftung2, Beschriftung3]\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def lade_bild(pfad): # Bild laden und vorverarbeiten\n",
        "  bild = cv2.imread(pfad, cv2.IMREAD_UNCHANGED) # bild lesen vom rgba-format\n",
        "  bild_in_grau = bild[:,:,3] # Alpha-Wert herausfiltern\n",
        "  bild_0_1 = bild_in_grau / 255 # bild zwischen 0 und 1 skalieren\n",
        "  return bild_0_1 # Bild an den Aufruf zurückgeben\n",
        "\n",
        "\n",
        "for zahl in range(10): # Wir haben ordner von 0 bis 9\n",
        "  pfad = \"dataset/\"+str(zahl)+\"/\"+str(zahl) + \"/\" # Pfad zusammenbauen\n",
        "  print(\"zahl ist\", zahl, \"- Der Pfad ist\", pfad)\n",
        "  alle_bilder_namen = os.listdir(pfad) # alle bilder im pfad auflisten\n",
        "  for name in alle_bilder_namen: # alle bilder in dem Ordner durchgehen\n",
        "    pfad_zum_bild = pfad + name \n",
        "    bild = lade_bild(pfad_zum_bild)\n",
        "\n",
        "    X.append(bild) # Das Bild an X anhängen\n",
        "    Y.append(zahl) # Die zugehörige Zahl an Y anhängen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Es gibt\", len(Y),\"Trainingsbilder\")"
      ],
      "metadata": {
        "id": "dbfx3ak8o2M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kMzl5UQg0KP"
      },
      "outputs": [],
      "source": [
        "index = 100000\n",
        "\n",
        "print(\"Es wird das Bild mit dem index\", index, \"angezeigt\")\n",
        "plt.imshow(X[index]), \n",
        "print(\"Y ist \", Y[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xNT0n6i01X8"
      },
      "outputs": [],
      "source": [
        "# listen in numpy arrays umwandeln\n",
        "Y = np.array(Y) # numpy arrays sind für viele Elemente eine bessere Speichermethode\n",
        "X = np.array(X) # tensorflow benötigt numpy arrays und kann nicht mit listen arbeiten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "für das Training werden die Trainingsdaten in Trainingsdaten und Validierungsdaten aufgeteilt. Das neuronale Netz wird auf 80% der Daten trainiert und auf die anderen 20% getestet. Wenn es auf den anderen 20% gut ist, hat das neuronale Netz das Konzept von den Bildern verstanden. wenn es nur auf den Trainingsdaten gut ist und die Testdaten nicht klassifizieren kann, hat es nicht gut gelernt. <br>Tensorflow nimmt immer die letzten x% im Datensatz als Validierungsdaten. In diesem Fall sind die letzten 20% alle Bilder der 8 und der 9. Es würde also von 0 - 7 alles lernen und auf 8 und 9 getestet werden. Das kann so nicht funktionieren, denn wenn das Netzwerk nie eine 8 oder 9 in den Trainingsdaten gesehen hat wird es lernen dass es solche Zahlen nicht gibt. Also müssen die Trainingsdaten gemischt werden um zufällige Zahlen als Validierungsdaten zu erhalten"
      ],
      "metadata": {
        "id": "aXOjWn5HpX-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X und Y gleichmäßig mischen\n",
        "# X und Y werden so gemischt, dass Y[index] die Zahl enthält die in X[index] gespeichert ist\n",
        "p = np.random.permutation(Y.shape[0]) \n",
        "X = X[p]\n",
        "Y = Y[p] "
      ],
      "metadata": {
        "id": "ZQANFYQ5pUyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tspW2wbat0GX"
      },
      "source": [
        "# Neuronales Netzwerk bauen und trainieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfSDw5Gat2rk"
      },
      "outputs": [],
      "source": [
        "inputlayer = tf.keras.layers.Input(shape=(28,28)) # unser Bild hat die Form [Höhe, Breite]\n",
        "platt = tf.keras.layers.Flatten()(inputlayer)\n",
        "x = tf.keras.layers.Dense(16,activation=\"relu\")(platt)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(16,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "output = tf.keras.layers.Dense(10,activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputlayer, output)\n",
        "print(\"\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V44YHlbXvwZP"
      },
      "outputs": [],
      "source": [
        "fehlerfunktion = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimierer = tf.keras.optimizers.SGD(0.001, momentum = 0.95)\n",
        "model.compile(optimierer, fehlerfunktion, metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S2tL87avxb-"
      },
      "outputs": [],
      "source": [
        "model.fit(X, Y, batch_size = 64, epochs = 5, validation_split = 0.2) # Parameter optimieren"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\") # Netzwerk und Parameter speichern"
      ],
      "metadata": {
        "id": "U9RCAaCTKeCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV5Ckw9ld6JM"
      },
      "source": [
        "# Test mit selbstgemaltem Bild\n",
        "Male eine Zahl mit Paint und lade das Bild in das Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifjD08Wod-Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "60588c44-f4c4-4407-faf7-13cbcd55f65f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALVUlEQVR4nO3dT4ge9R3H8c/HP7kYD0lDlyXGxpZcQg5aQughFHswpLmsXkRPqRbWgxaFHhrsQUEKUlp7LEQMSYtVBLUGqdU0SONJsoqNSRZNKgkmrFmXHFxP1uTbwzORNT7/8szMM7P7fb/g4XmemeeZ+e6wn/39ZmZnfo4IAVj5rmu6AADjQdiBJAg7kARhB5Ig7EASN4xzZbY59A/ULCLcbXqplt32Ttsf2T5te0+ZZQGol0c9z277ekkfS7pL0jlJRyXdHxEn+3yHlh2oWR0t+zZJpyPik4j4StKLkqZKLA9AjcqEfb2kT5e8P1dM+xbb07ZnbM+UWBeAkmo/QBcReyXtlejGA00q07Kfl7RhyftbimkAWqhM2I9K2mT7NturJN0n6WA1ZQGo2sjd+Ij42vYjkt6UdL2kfRFxorLKAFRq5FNvI62MfXagdrX8Uw2A5YOwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkxnoraeTT76pKu+vFWagJLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF5dpQy6O7EU1MM/9cWtOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATn2dHXoPPog65J53r29igVdttnJC1KuiTp64jYWkVRAKpXRcv+s4hYqGA5AGrEPjuQRNmwh6S3bL9ne7rbB2xP256xPVNyXQBK8KADMH2/bK+PiPO2vy/pkKRfRcSRPp8ffWVoBAfolp+I6LphS7XsEXG+eJ6X9KqkbWWWB6A+I4fd9k22b77yWtIOScerKgxAtcocjZ+Q9GrRFbtB0t8i4p+VVIXKlO2G09VeOUrts1/zythnH7uyYa9z/fwhqUct++wAlg/CDiRB2IEkCDuQBGEHkuAS1xWg3+2aL126VOu6t2zZUuvyUR1adiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsy8Di4mLf+atXr+45r+4ry1atWtV3/htvvFHr+jE8WnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIK7y47BoGvKr7uu/9/cNt+FddDvz+zsbM95mzdvrrociLvLAukRdiAJwg4kQdiBJAg7kARhB5Ig7EASnGevQNlt2Obz6IOU+dmX88/dZiOfZ7e9z/a87eNLpq21fcj2qeJ5TZXFAqjeMN34/ZJ2XjVtj6TDEbFJ0uHiPYAWGxj2iDgi6eJVk6ckHSheH5B0d8V1AajYqPegm4iIueL1Z5Imen3Q9rSk6RHXA6AipW84GRHR78BbROyVtFdauQfogOVg1FNvF2xPSlLxPF9dSQDqMGrYD0raXbzeLem1asoBUJeB59ltvyDpTknrJF2Q9ISkv0t6SdKtks5Kujcirj6I121ZK7IbP8Q2HFMl47du3bq+8z///POe81bydmlSr/Ps/FNNBQh7b4R9/Lh5BZAcYQeSIOxAEoQdSIKwA0kwZHMFMh9VXlhY6Du/362kMV607EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZUUrmK/6WG1p2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC8+zoa5x3H0a9aNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQxMOy299met318ybQnbZ+3/UHx2FVvmQDKGqZl3y9pZ5fpf4qI24vHP6otC0DVBoY9Io5IujiGWgDUqMw++yO2jxXd/DW9PmR72vaM7ZkS6wJQkoe50MH2RkmvR8SW4v2EpAVJIekpSZMR8eAQy+GqimWm7IUw3HBy/CKi60YfqWWPiAsRcSkiLkt6VtK2MsUBqN9IYbc9ueTtPZKO9/osgHYYeD277Rck3Slpne1zkp6QdKft29Xpxp+R9FCNNQKowFD77JWtjH32ZYd99uWn0n12AMsPYQeSIOxAEoQdSIKwA0lwK2n0tX///r7zH3jggfEUgtJo2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa56Q1+Dfj+4qq19uOoNSI6wA0kQdiAJwg4kQdiBJAg7kARhB5Lgevbkxvl/FmgWLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF5dvS1Y8eOpktARQa27LY32H7b9knbJ2w/Wkxfa/uQ7VPF85r6ywUwqmG68V9L+nVEbJb0E0kP294saY+kwxGxSdLh4j2AlhoY9oiYi4j3i9eLkmYlrZc0JelA8bEDku6uq0gA5V3TPrvtjZLukPSupImImCtmfSZposd3piVNj14igCoMfTTe9mpJL0t6LCK+WDovOldTdL2iIiL2RsTWiNhaqlIApQwVdts3qhP05yPilWLyBduTxfxJSfP1lAigCgO78e7cK/g5SbMR8cySWQcl7Zb0dPH8Wi0VolbcCjqPgfeNt71d0juSPpR0uZj8uDr77S9JulXSWUn3RsTFAcvi4mmgZr3uG88gEcAKwyARQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDEw7LY32H7b9knbJ2w/Wkx/0vZ52x8Uj131lwtgVMOMzz4paTIi3rd9s6T3JN0t6V5JX0bEH4ZeGUM2A7XrNWTzDUN8cU7SXPF60faspPXVlgegbte0z257o6Q7JL1bTHrE9jHb+2yv6fGdadsztmdKVQqglIHd+G8+aK+W9G9Jv4uIV2xPSFqQFJKeUqer/+CAZdCNB2rWqxs/VNht3yjpdUlvRsQzXeZvlPR6RGwZsBzCDtSsV9iHORpvSc9Jml0a9OLA3RX3SDpetkgA9RnmaPx2Se9I+lDS5WLy45Lul3S7Ot34M5IeKg7m9VsWLTtQs1Ld+KoQdqB+I3fjAawMhB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQG3nCyYguSzi55v66Y1kZtra2tdUnUNqoqa/tBrxljvZ79Oyu3ZyJia2MF9NHW2tpal0RtoxpXbXTjgSQIO5BE02Hf2/D6+2lrbW2tS6K2UY2ltkb32QGMT9MtO4AxIexAEo2E3fZO2x/ZPm17TxM19GL7jO0Pi2GoGx2frhhDb9728SXT1to+ZPtU8dx1jL2GamvFMN59hhlvdNs1Pfz52PfZbV8v6WNJd0k6J+mopPsj4uRYC+nB9hlJWyOi8X/AsP1TSV9K+suVobVs/17SxYh4uvhDuSYiftOS2p7UNQ7jXVNtvYYZ/4Ua3HZVDn8+iiZa9m2STkfEJxHxlaQXJU01UEfrRcQRSRevmjwl6UDx+oA6vyxj16O2VoiIuYh4v3i9KOnKMOONbrs+dY1FE2FfL+nTJe/PqV3jvYekt2y/Z3u66WK6mFgyzNZnkiaaLKaLgcN4j9NVw4y3ZtuNMvx5WRyg+67tEfFjST+X9HDRXW2l6OyDtenc6Z8l/UidMQDnJP2xyWKKYcZflvRYRHyxdF6T265LXWPZbk2E/bykDUve31JMa4WIOF88z0t6VZ3djja5cGUE3eJ5vuF6vhERFyLiUkRclvSsGtx2xTDjL0t6PiJeKSY3vu261TWu7dZE2I9K2mT7NturJN0n6WADdXyH7ZuKAyeyfZOkHWrfUNQHJe0uXu+W9FqDtXxLW4bx7jXMuBredo0Pfx4RY39I2qXOEfn/SvptEzX0qOuHkv5TPE40XZukF9Tp1v1PnWMbv5T0PUmHJZ2S9C9Ja1tU21/VGdr7mDrBmmyotu3qdNGPSfqgeOxqetv1qWss241/lwWS4AAdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxf8lx2AMUcaeuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "bild = cv2.imread(\"Untitled.png\", cv2.IMREAD_GRAYSCALE) # bild mit dem Namen untitled.png lesen im graustufen-format\n",
        "bild = cv2.resize(bild, (28,28))\n",
        "bild_0_1 = 1 - bild / 255 # bild zwischen 0 und 1 skalieren\n",
        "plt.imshow(bild_0_1, cmap = \"gray\")\n",
        "bild_0_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKZb7f-FegmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfb1b16-2f03-4059-a46a-e3bf076a908a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Entscheidungen sind: tf.Tensor(\n",
            "[[0.01312716 0.6096637  0.00884979 0.1081872  0.00640199 0.02641728\n",
            "  0.03351263 0.16607414 0.0094393  0.01832683]], shape=(1, 10), dtype=float32)\n",
            "Das ist die Zahl: 1\n"
          ]
        }
      ],
      "source": [
        "bild_batch = np.reshape(bild_0_1,(1,28,28)) # tensorflow braucht ein array von Inputs\n",
        "\n",
        "entscheidungen = model(bild_batch)\n",
        "print(\"Die Entscheidungen sind:\", entscheidungen)\n",
        "print(\"Das ist die Zahl:\", np.argmax(entscheidungen))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "erstes neuronales Netz.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1u0d27wW+4l0jVQKJoc90",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}